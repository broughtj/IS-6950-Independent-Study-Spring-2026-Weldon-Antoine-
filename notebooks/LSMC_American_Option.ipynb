{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# American Option Pricing via Least-Squares Monte Carlo (LSMC)\n",
        "\n",
        "This notebook demonstrates the **Dynamic Programming** principles discussed in the Chapter 10 notes. We implement the **Longstaff-Schwartz algorithm** (LSMC) to price an American Put option using **JAX** for high-performance path simulation.\n",
        "\n",
        "## The DP Connection\n",
        "- **Backward Induction**: We start at expiration and move backward to the present.\n",
        "- **Value Function Approximation**: We use regression to approximate the \"Continuation Value\" (the conditional expectation of future payoffs).\n",
        "- **Optimal Control**: At each step, we make the optimal choice: Exercise Now vs. Hold (Continue)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup JAX for CPU/TPU\n",
        "print(f\"JAX Devices: {jax.devices()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Parameter Specification\n",
        "We model a standard American Put option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S0 = 100.0      # Initial stock price\n",
        "K = 100.0       # Strike price\n",
        "T = 1.0         # Time to maturity\n",
        "r = 0.05        # Risk-free rate\n",
        "sigma = 0.2     # Volatility\n",
        "n_steps = 50    # Number of time steps\n",
        "n_paths = 50000 # Number of simulated paths\n",
        "dt = T / n_steps\n",
        "df = jnp.exp(-r * dt) # Discount factor per step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Forward Simulation (GBM)\n",
        "Using JAX to simulate Geometric Brownian Motion paths efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_paths(key, n_paths, n_steps, S0, r, sigma, dt):\n",
        "    \"\"\"Simulate GBM paths using JAX.\"\"\"\n",
        "    # Generate random normal increments\n",
        "    z = jax.random.normal(key, (n_paths, n_steps))\n",
        "    \n",
        "    # Calculate log returns\n",
        "    log_returns = (r - 0.5 * sigma**2) * dt + sigma * jnp.sqrt(dt) * z\n",
        "    \n",
        "    # Cumulative sum of log returns to get price paths\n",
        "    cumulative_log_returns = jnp.cumsum(log_returns, axis=1)\n",
        "    \n",
        "    # Add starting price\n",
        "    paths = S0 * jnp.exp(jnp.hstack([jnp.zeros((n_paths, 1)), cumulative_log_returns]))\n",
        "    return paths\n",
        "\n",
        "key = jax.random.PRNGKey(42)\n",
        "paths = simulate_paths(key, n_paths, n_steps, S0, r, sigma, dt)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(paths[:100].T, lw=0.5, alpha=0.6)\n",
        "plt.title(\"First 100 Simulated GBM Paths\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Backward Induction (LSMC)\n",
        "We implement the core DP logic. At each step $t$, we approximate the continuation value using a polynomial regression on paths that are currently In-The-Money (ITM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def put_payoff(S, K):\n",
        "    \"\"\"Payoff function for a Put option.\"\"\"\n",
        "    return jnp.maximum(K - S, 0.0)\n",
        "\n",
        "def lsmc_american_put(paths, K, r, dt):\n",
        "    \"\"\"\n",
        "    Longstaff-Schwartz LSMC Algorithm for American Put.\n",
        "    \n",
        "    This is approximate Dynamic Programming in action:\n",
        "    - Backward induction from expiration\n",
        "    - Regression to approximate continuation value (value function)\n",
        "    - Optimal stopping decision at each time step\n",
        "    \"\"\"\n",
        "    n_paths, n_steps_plus_one = paths.shape\n",
        "    n_steps = n_steps_plus_one - 1\n",
        "    \n",
        "    # Initialize cash flows at expiration\n",
        "    cash_flow = put_payoff(paths[:, -1], K)\n",
        "    exercise_time = jnp.full(n_paths, n_steps)\n",
        "    \n",
        "    # Move backward from T-1 to 1 (not 0, as we price at t=0)\n",
        "    for t in range(n_steps - 1, 0, -1):\n",
        "        S_t = paths[:, t]\n",
        "        \n",
        "        # Identify In-The-Money paths\n",
        "        itm_mask = S_t < K\n",
        "        \n",
        "        if jnp.sum(itm_mask) > 0:\n",
        "            # Extract ITM paths\n",
        "            X = S_t[itm_mask]\n",
        "            \n",
        "            # Discounted future cash flows for ITM paths\n",
        "            discount_steps = exercise_time[itm_mask] - t\n",
        "            Y = cash_flow[itm_mask] * jnp.exp(-r * dt * discount_steps)\n",
        "            \n",
        "            # Regression: Approximate continuation value\n",
        "            # Using polynomial basis: [1, X, X^2]\n",
        "            A = jnp.column_stack([jnp.ones_like(X), X, X**2])\n",
        "            beta, _, _, _ = jnp.linalg.lstsq(A, Y, rcond=None)\n",
        "            \n",
        "            # Predicted continuation value\n",
        "            continuation_value = A @ beta\n",
        "            \n",
        "            # Exercise value\n",
        "            exercise_value = put_payoff(X, K)\n",
        "            \n",
        "            # Optimal decision: exercise if immediate value > continuation\n",
        "            exercise_now = exercise_value > continuation_value\n",
        "            \n",
        "            # Update cash flows and exercise times for paths that exercise\n",
        "            itm_indices = jnp.where(itm_mask)[0]\n",
        "            exercise_indices = itm_indices[exercise_now]\n",
        "            \n",
        "            cash_flow = cash_flow.at[exercise_indices].set(exercise_value[exercise_now])\n",
        "            exercise_time = exercise_time.at[exercise_indices].set(t)\n",
        "    \n",
        "    # Discount all cash flows back to t=0\n",
        "    discounted_payoffs = cash_flow * jnp.exp(-r * dt * exercise_time)\n",
        "    \n",
        "    return jnp.mean(discounted_payoffs)\n",
        "\n",
        "american_put_price = lsmc_american_put(paths, K, r, dt)\n",
        "print(f\"American Put Price: {american_put_price:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comparison with European Option\n",
        "To verify the \"Early Exercise Premium\" (the value of the real option flexibility)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# European Put: Simply discount the payoff at expiration\n",
        "european_payoff = put_payoff(paths[:, -1], K)\n",
        "european_price = jnp.mean(european_payoff) * jnp.exp(-r * T)\n",
        "\n",
        "# Early Exercise Premium\n",
        "early_exercise_premium = american_put_price - european_price\n",
        "\n",
        "print(f\"European Put Price: {european_price:.4f}\")\n",
        "print(f\"American Put Price: {american_put_price:.4f}\")\n",
        "print(f\"Early Exercise Premium: {early_exercise_premium:.4f} ({early_exercise_premium/european_price:.2%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n",
        "\n",
        "This notebook demonstrates the core ideas from Chapter 10:\n",
        "\n",
        "1. **Backward Induction**: We started at expiration and worked backward, making optimal decisions at each step.\n",
        "2. **Value Function Approximation**: We used polynomial regression to approximate the continuation value—the expected discounted future payoff.\n",
        "3. **Optimal Stopping**: At each time step, we compared the immediate exercise value to the continuation value and chose the better option.\n",
        "\n",
        "> **The DP Insight**: The early exercise premium represents the *value of flexibility*—the option to act optimally in the future rather than being locked into a single strategy."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
